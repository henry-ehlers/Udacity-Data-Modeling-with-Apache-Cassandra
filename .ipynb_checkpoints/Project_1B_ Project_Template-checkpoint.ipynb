{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "print(len(full_data_rows_list))\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a connection to the Cassandra cluster\n",
    "from cassandra.cluster import Cluster\n",
    "try: \n",
    "    cluster = Cluster() #If you have a locally installed Apache Cassandra instance\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the keyspace to which we should connect\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS udacity \n",
    "        WITH REPLICATION = { \n",
    "            'class'              : 'SimpleStrategy', \n",
    "            'replication_factor' : 1 \n",
    "        } \n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set the current session to the previously defined keyspace\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Query #1 \n",
    "\n",
    "The goal here is to retreive the following: the name of artist, the song (sorted by the number of items in a user's session) and user's first and last name, for the specific user_id = 10 and their session_id = 182.\n",
    "\n",
    "### Create and Populate the Database\n",
    "\n",
    "To facilitate the query above, the database will contain the following fields: session_id, items_in_session, artist, song, length (of song). In order to ensure that each user's songs listened to are uniquely identifiable within this table, the primary key is composite, constisting of the session_id and the items_in_session, where session_id functions as partition key, and items_in_session as clustering key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop table if it already exists just to make sure we can overwrite it if needed\n",
    "query = \"\"\"DROP TABLE IF EXISTS song_info;\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Create Table\n",
    "query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS song_info\n",
    "    (session_id int, items_in_session int, artist varchar, song varchar, length float, \n",
    "        PRIMARY KEY ((session_id), items_in_session));\n",
    "\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populate the table with data from the CSV file\n",
    "\n",
    "# Define the query  necessary to fill the table\n",
    "file = 'event_datafile_new.csv'\n",
    "query = \"\"\"\n",
    "            INSERT INTO song_info\n",
    "            (session_id, items_in_session, artist, song, length)\n",
    "            VALUES (%s, %s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "\n",
    "# Open the CSV file\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    \n",
    "    # Read each line except the first (header)\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) \n",
    "    \n",
    "    # Iterate over each line in the CSV file\n",
    "    for line in csvreader:\n",
    "        \n",
    "        ## Extract the relevant fields from the CSV file line\n",
    "        artist           = line[0]\n",
    "        items_in_session = line[3]\n",
    "        length           = line[5]\n",
    "        session_id       = line[8]\n",
    "        song             = line[9]\n",
    "        \n",
    "        # Insert the extracted information into the table\n",
    "        try:\n",
    "            session.execute(query, (int(session_id), int(items_in_session), artist, song, float(length) ))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### SELECT the necessary data using an appropriate query\n",
    "\n",
    "As reminder, the goal here is to retreive the following: the name of artist, the song (sorted by the number of items in a user's session) and user's first and last name, for the specific user_id = 10 and their session_id = 182."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless - Music Matters (Mark Knight Dub) - 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "# Define a query to select the artist, song, and song length listened to in session 338 with 4 items in its session\n",
    "query = \"\"\"\n",
    "    SELECT artist, song, length FROM song_info \n",
    "        WHERE session_id       = 338 \n",
    "        AND   items_in_session = 4;\n",
    "\"\"\"\n",
    "try:\n",
    "    query_hit = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "# Iterate over all hits from the previous query and print their outcome   \n",
    "for hit in query_hit:\n",
    "    print(hit.artist, \"-\", hit.song, \"-\", hit.length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Query #2 \n",
    "\n",
    "The goal here is to retreive the following: the name of the artist, the song(s) sorted by the number of items in a user's session, and the user's first and last name, for the specific user_id = 10 and session_id = 182.\n",
    "\n",
    "### Create and Populate the Database\n",
    "\n",
    "In order to nesure that we can uniquely identify each song, and its associated artist, as well as the user that listened to it in that particular session, no matter the number of items within the session, this database has a composite key constisting of the composite partition key user_id and session_id, as the clusteriong column of items_in_session. The additional fields of first_name, last_name, artist, and song are the information we are ultimately after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create and Populate the Table\n",
    "\n",
    "# Drop table if it already exists just to make sure we can overwrite it if needed\n",
    "query = \"\"\"DROP TABLE IF EXISTS user_song_info;\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Create Table\n",
    "query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS user_song_info\n",
    "    (user_id int, session_id int, items_in_session int, \n",
    "    first_name varchar, last_name varchar, artist varchar, song varchar, \n",
    "        PRIMARY KEY ((user_id, session_id), items_in_session))\n",
    "\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Query needed to fill table using the CSV FILE\n",
    "file = 'event_datafile_new.csv'\n",
    "query = \"\"\"\n",
    "    INSERT INTO user_song_info\n",
    "        (user_id, session_id, items_in_session, first_name, last_name, artist, song)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "\n",
    "# Open the CSV file\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    \n",
    "    # read each line except the first\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    \n",
    "    # Iterate over each line\n",
    "    for line in csvreader:\n",
    "        \n",
    "        ## Extract the relevant fields from the CSV file line\n",
    "        artist           = line[0]\n",
    "        first_name       = line[1]\n",
    "        items_in_session = line[3]\n",
    "        last_name        = line[4]\n",
    "        session_id       = line[8]\n",
    "        song             = line[9]\n",
    "        user_id          = line[10]\n",
    "        \n",
    "        # Add the line's relevant information to the table\n",
    "        try:\n",
    "            session.execute(query, (int(user_id), int(session_id), int(items_in_session), first_name, last_name, artist, song ))\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### SELECT the neccesary data using an appropriate query\n",
    "\n",
    "As a reminder, the goal here is to retreive the following: the name of the artist, the song(s) sorted by the number of items in a user's session, and the user's first and last name, for the specific user_id = 10 and session_id = 182."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone - Keep On Keepin' On - Sylvie Cruz\n",
      "Three Drives - Greece 2000 - Sylvie Cruz\n",
      "Sebastien Tellier - Kilometer - Sylvie Cruz\n",
      "Lonnie Gordon - Catch You Baby (Steve Pitron & Max Sanna Radio Edit) - Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# Extract the desired fields from the table\n",
    "query = \"\"\"\n",
    "    SELECT artist, song, first_name, last_name FROM user_song_info\n",
    "        WHERE user_id    = 10 \n",
    "        AND   session_id = 182\n",
    "    ORDER BY items_in_session;\n",
    "\"\"\"\n",
    "try:\n",
    "    query_hit = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Iterate over all hits from the previous query and print their outcome\n",
    "for hit in query_hit:\n",
    "    print(hit.artist, \"-\", hit.song, \"-\", hit.first_name, hit.last_name)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Query #3\n",
    "The goal here is to retreive the following: the first and last name of every user which (at some point in their listening history) listened to the song \"All Hands Against His Own\".\n",
    "\n",
    "### Create and Populate the Database\n",
    "\n",
    "In order to keep track of what users listened to what songs, this database's composite primary key consists (unsurprisingly) of the song and each user's unique id. This way, the database can allow for the identification of each user's first and last name, if they listened to a particular song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the Table\n",
    "\n",
    "# Drop table if it already exists just to make sure we can overwrite it if needed\n",
    "query = \"\"\"DROP TABLE IF EXISTS song_listen_info\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Create Table\n",
    "query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS song_listen_info\n",
    "        (song varchar, user_id int, first_name varchar, last_name varchar, \n",
    "        PRIMARY KEY (song, user_id));\n",
    "\"\"\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Fill table using the CSV FILE\n",
    "file = 'event_datafile_new.csv'\n",
    "query = \"\"\"\n",
    "    INSERT INTO song_listen_info \n",
    "        (song, user_id, first_name, last_name) \n",
    "        VALUES (%s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "# Iterate over each line in the input CSV and populate the database\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    \n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        \n",
    "        ## Extract the relevant fields from the CSV file line\n",
    "        first_name       = line[1]\n",
    "        last_name        = line[4]\n",
    "        song             = line[9]\n",
    "        user_id          = line[10]\n",
    "        \n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        try:\n",
    "            session.execute(query, (song, int(user_id), first_name, last_name))\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Select the data using an appropriate query\n",
    "\n",
    "As a reminder, the goal here is to retreive the following: the first and last name of every user which (at some point in their listening history) listened to the song \"All Hands Against His Own\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "# Select the desired entiers\n",
    "query = \"\"\"\n",
    "    SELECT first_name, last_name FROM song_listen_info\n",
    "        WHERE song = 'All Hands Against His Own';\n",
    "\"\"\"\n",
    "try:\n",
    "    query_hit = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "# Iterate over all hits from the previous query and print their outcome\n",
    "for hit in query_hit:\n",
    "    print(hit.first_name, hit.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the tables to be dropped\n",
    "tables = [\"song_info\", \"user_song_info\", \"song_listen_info\"]\n",
    "query  = \"\"\"DROP TABLE IF EXISTS {}\"\"\"\n",
    "\n",
    "# Iterate over each table and drop (if possible)\n",
    "for table in tables:\n",
    "    try:\n",
    "        session.execute(query.format(table))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
